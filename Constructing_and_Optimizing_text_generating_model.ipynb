{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Constructing_and_Optimizing_text_generating_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4nfenQTTJo2wM1BBcE50T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoVal1/Constructing_and_Optimizing_Text_Generating_Model/blob/main/Constructing_and_Optimizing_text_generating_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCnKO7hlq0MN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Constructing and Optimizing the Text Generation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxhW3mtLmfb"
      },
      "source": [
        "Dataset: [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfdd08d0-1fa8-49b3-ab31-b9646329f5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-07 23:39:20--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.125.102, 108.177.125.100, 108.177.125.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.125.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/4r7abe2ha1ftub1bot2basic27s1podj/1659915525000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=c48d1be3-2650-4d5d-9dd5-066ee771ebb4 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-08-07 23:39:26--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/4r7abe2ha1ftub1bot2basic27s1podj/1659915525000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=c48d1be3-2650-4d5d-9dd5-066ee771ebb4\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 142.250.157.132, 2404:6800:4008:c13::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|142.250.157.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M  86.8MB/s    in 0.8s    \n",
            "\n",
            "2022-08-07 23:39:27 (86.8 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9x-7dWihxx"
      },
      "source": [
        "## 250 Songs\n",
        "\n",
        "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
        "\n",
        "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbMN_19jfRT"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LRmPPJegovBe"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kIGedF3XjHj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c8eed8-00b2-4ad6-dd95-6934b7ba888b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quoDmw_FkNBA"
      },
      "source": [
        "### Create Sequences and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kkLAf3HmkPSo"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cECbqT-blMk-"
      },
      "source": [
        "### Train a (Better) Text Generation Model\n",
        "\n",
        "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7nHOp6uWlP_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2470251-c650-4c4d-b7fa-1c4bc598a0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 35s 20ms/step - loss: 5.9831 - accuracy: 0.0468\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 5.6968 - accuracy: 0.0500\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 5.4932 - accuracy: 0.0683\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 5.2716 - accuracy: 0.1009\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 5.1299 - accuracy: 0.1124\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 5.0043 - accuracy: 0.1252\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 4.8851 - accuracy: 0.1365\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 4.7771 - accuracy: 0.1479\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 4.6712 - accuracy: 0.1588\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 4.5741 - accuracy: 0.1696\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 4.4846 - accuracy: 0.1800\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 4.3975 - accuracy: 0.1921\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 4.3183 - accuracy: 0.2000\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 4.2474 - accuracy: 0.2085\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 4.1818 - accuracy: 0.2161\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 4.1221 - accuracy: 0.2234\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 4.0651 - accuracy: 0.2302\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 4.0113 - accuracy: 0.2379\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.9514 - accuracy: 0.2476\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.8882 - accuracy: 0.2563\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 3.8266 - accuracy: 0.2655\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.7658 - accuracy: 0.2738\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 3.7063 - accuracy: 0.2834\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.6502 - accuracy: 0.2925\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.5943 - accuracy: 0.2997\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 3.5379 - accuracy: 0.3094\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.4881 - accuracy: 0.3166\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 3.4420 - accuracy: 0.3223\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.3978 - accuracy: 0.3287\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.3626 - accuracy: 0.3338\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 3.3230 - accuracy: 0.3381\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.2903 - accuracy: 0.3447\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 3.2541 - accuracy: 0.3501\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.2228 - accuracy: 0.3560\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.1932 - accuracy: 0.3600\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 3.1641 - accuracy: 0.3636\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.1332 - accuracy: 0.3688\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 3.1109 - accuracy: 0.3735\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.0809 - accuracy: 0.3765\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 3.0559 - accuracy: 0.3821\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 3.0305 - accuracy: 0.3861\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 3.0058 - accuracy: 0.3915\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.9832 - accuracy: 0.3930\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.9608 - accuracy: 0.3976\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.9379 - accuracy: 0.3999\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.9180 - accuracy: 0.4037\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.8953 - accuracy: 0.4074\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.8726 - accuracy: 0.4119\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.8521 - accuracy: 0.4151\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.8348 - accuracy: 0.4170\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.8143 - accuracy: 0.4209\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.7954 - accuracy: 0.4243\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.7812 - accuracy: 0.4255\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.7594 - accuracy: 0.4300\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.7460 - accuracy: 0.4314\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.7283 - accuracy: 0.4347\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.7111 - accuracy: 0.4388\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.6928 - accuracy: 0.4416\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.6761 - accuracy: 0.4438\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.6637 - accuracy: 0.4456\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.6482 - accuracy: 0.4487\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.6353 - accuracy: 0.4506\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.6225 - accuracy: 0.4520\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.6041 - accuracy: 0.4572\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.5898 - accuracy: 0.4605\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.5810 - accuracy: 0.4622\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.5682 - accuracy: 0.4635\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.5541 - accuracy: 0.4631\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.5461 - accuracy: 0.4662\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.5291 - accuracy: 0.4697\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.5229 - accuracy: 0.4702\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.5087 - accuracy: 0.4721\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.4961 - accuracy: 0.4742\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.4860 - accuracy: 0.4767\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.4753 - accuracy: 0.4775\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.4634 - accuracy: 0.4794\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.4550 - accuracy: 0.4818\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.4451 - accuracy: 0.4835\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.4358 - accuracy: 0.4849\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 30s 20ms/step - loss: 2.4203 - accuracy: 0.4879\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.4177 - accuracy: 0.4864\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.4042 - accuracy: 0.4897\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.3973 - accuracy: 0.4910\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.3857 - accuracy: 0.4939\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.3815 - accuracy: 0.4939\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.3694 - accuracy: 0.4968\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.3636 - accuracy: 0.4972\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.3536 - accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.3421 - accuracy: 0.5020\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 29s 19ms/step - loss: 2.3328 - accuracy: 0.5020\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.3254 - accuracy: 0.5039\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.3238 - accuracy: 0.5040\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.3113 - accuracy: 0.5072\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.3074 - accuracy: 0.5071\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.3005 - accuracy: 0.5087\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.2919 - accuracy: 0.5093\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.2818 - accuracy: 0.5138\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.2806 - accuracy: 0.5121\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 29s 20ms/step - loss: 2.2664 - accuracy: 0.5154\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 28s 19ms/step - loss: 2.2615 - accuracy: 0.5160\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvIz20nlQcq"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rOqmmarvlSLh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f9517af4-874b-4438-adde-dda01c1856b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5bn+8e+ThIRAgIR5SEJAZgEBw+BQW1Fb1Fa0ttZqrVotdrDaVlu1nlNb6zm1etpT7fFXa6ljq+JUS61KFWelSBhkDDOBMCYkBBLIuJ/fH9lopCAbyMreybo/15WLvdZeO/tZrCT3Xu/7rneZuyMiIuGVFO8CREQkvhQEIiIhpyAQEQk5BYGISMgpCEREQi4l3gUcqe7du3teXl68yxARaVXmz59f6u49DvZcqwuCvLw8CgoK4l2GiEirYmZFh3pOTUMiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhFyru45ARCQM3J3FxRVs2bWP0soaSitrOWN4T0ZnZzb7eykIRETiaNX2PTy/cDPH9cggPy+Lnp3a8/yizTz4znpW76j82LY9OqUpCERE2oq9tfXcO3sN099eR33koxuEpSQZ9RHn+L6duftLoxnZrwvdMlLp2iGVlORgWvMVBCIiAavYV8fCjeWs3LaHnVW1lFbWMHddGZt37eOi/Gx+PGUYOytrKSgqY11JFWeN6MXEAV0xsxapT0EgItJM1uzYwyPvFbF4cwUpSUZyklFeVcuakkr23xW4fbskunVMI6drOr+56AQmDuwGQPeMNIb27hSXugMNAjObAtwDJAPT3f3OA56/Argb2Bxd9X/uPj3ImkREjlV5VS3/WreTLRXVRCJOXSTCnLU7eXt1KakpSeT3zyLJjPpIhNyuHZg6pi/jcrMYmd2FTmkpLfZJP1aBBYGZJQP3AWcBxcA8M5vp7ssP2HSGu18bVB0iIkdjX20D728o41/rdlJeVUtDxGlwp3DrHlZs2/3hJ/z9enduz48+N5SLx+fQLSMtPkUfpSDPCCYAa9x9HYCZPQlMBQ4MAhGRhFBd18CsZdt4uqCY99eXUdsQoV2y0bVjKklmJJmRnZXOD84cwimDunFcjwxSkpNINiMtJYmkpMT6pB+rIIOgH7CpyXIxMPEg211oZqcBq4AfuPumAzcws2nANIDc3NwAShWRsCmrquXlpdvYWVlDZW09OytreWX5dir21ZHTNZ0rTsnjlEHdGZ+XRYfUtt2dGu+9+zvwhLvXmNk1wCPA5AM3cvcHgAcA8vPz/cDnRUQOJRJxVu3YQ11945+Osr21PDu/mJeXbqO2IQJAakoSGWkpfHpIDy4en8Okgd1a7af7oxFkEGwGcposZ/NRpzAA7r6zyeJ04K4A6xGRENmxp5qnC4p5ct5GNpXt+9hzndqncMnEXC6ekMNxPTJoF9D4/NYiyCCYBww2swE0BsDFwCVNNzCzPu6+Nbp4HrAiwHpEpA1bX1rFi0u2UrhtDyu37WZtSRUNEeekgd24bvJgsjqkAtAuJYkJeV1JT02Oc8WJI7AgcPd6M7sWmEXj8NEH3X2Zmd0OFLj7TOA6MzsPqAfKgCuCqkdEWr+SPTU8VbCJdSVVjOrXmTG5WdQ1RJj+9jr+uXw77pCdlc6w3p2YMrIP54/py8AeGfEuO+GZHzgGKsHl5+e7bl4vEg6RiFNcvo9lWyp4aek2Xlq6lboGp1vHVHZW1X64XZf0dlw2qT9fP6k/PTu3j2PFicvM5rt7/sGei3dnsYjIh6rrGli0aRdz15Uxd/1OlhRXsKemHmhs179sUh6XTsrluB4ZbK3Yx6KNu6isqeecUX3omKY/Z0dL/3MiEleVNfW8sXIHLy3dxhuFO6iqbcAMhvfuzNSxfTm+bxdG9OnM0N6daN/uo3b9Pl3S6TMqPY6Vtx0KAhFpEe7O7up6tu+uZsuufSwoKue9tTtZtGkX9RGne0YqU8f24/ShPZmQ15UuHdrFu+TQUBCISGAaIs7768uY+cEWZi3bRlmTdv0kg1HZmUw7bSCfHtKD/LyuJIdo7H4iURCISLPaU13Hu2tKeWNlCa8V7mDHnho6pCZz5vBejM7uQs/O7enduT1De3eiS7o+9ScCBYGIHJWGiLNrby3le2vZsqua99eXMWfdTj6INvV0SkvhU0O6c/bIPpwxvGebn6ahNdOREZEjUrhtN/e/sZYXFm/92J21kpOMUf268M3TBvKZIT0Y1z8r9FfsthYKAhE5LHdnztqdTH9nPa8V7qBjajKXTGwcxpnVMZXuGamMzs4kQ0M4WyUdNRH5UGllDYVb97B9dzUdUpNJT01mU/k+HpuzgVXbK+naMZUbzhrCZSf1JzM6ZYO0fgoCkZCqrmtgwcZyFhSVM7+onCWbd1NaWXPQbUf2a7yR+hdO6PuxsfzSNigIREKmtLKGR+cU8dicDZTvrQNgcM8MPjO0B8P7dGZ47070yUynuq6BvbUNdEhNZljvTgl3e0VpPgoCkZCormvg1/9cyaNziqipj3Dm8F58dUIO+f118VbYKQhEQqBw226uf2IRK7fv4csnZnPNp49jUE/NyimNFAQibZC7s2NPDcu37GbehjKmv7Oezu3b8fCV4/nM0J7xLk8SjIJApI3YvGsf76wu4b21O5mzdic79nzU8Xvm8F7ceeEoumekxbFCSVQKApFWbP/4/gffXc/swh24Q/eMNE46rhsn5mYyom8XhvXpROf26gOQQ1MQiLQyO3ZXM3d9GQUbynhnTSlrS6ro1jGVa08fxHkn9GVQzwyN8JEjoiAQSXDuztLNu3llxXZeXb6d5Vt3A9AhNZlxuVlc8+njOE/j++UYKAhEElRZVS3PLShmxrxNrN5RSZLBif2zuGnKME4Z1I0RfTqTorl8pBkoCEQSTHlVLb97bQ1//lcRtQ0RxuZmcucXR/HZ43vTtaOmdZDmpyAQSRDVdQ08OmcDv3ttDVU19Xz5xBy+ceoAhvbuFO/SpI1TEIjE2a69tTw6p4hH3tvAzqpaPjO0B7ecPVwBIC1GQSDSwir21jG7cDuF2/awYutu5heVs7e2gcnDenLNaQOZOLBbvEuUkFEQiLQQd+f5RZu544UV7KyqJTUliSG9MrhgbD8uO6k/w3p3jneJElIKApEARSLO5l37WLV9Dw++u5531+xkTE4mf7w8n9H9umjUjyQEBYFIAOYXlfHAW+t4e3Upe2sbAOjUPoU7zh/JJRNySUrSBV+SOBQEIs3E3Xl95Q7ue30t84vKyezQjgvHZTO8T2eG9MpgWJ/OupWjJCT9VIo0g/lF5fzqpULe31BGdlY6P/vCCC4an0OHVP2KSeLTT6nIUYhEnOVbd/PumlLeWFnCnHU76Z6Rxh3nj+Qr43Nop7Z/aUUUBCJHoLyqlsff38hjc4rYtrsagKG9OnHjZ4dw5SkD6KimH2mF9FMrEoPyqlr+99VVPFWwieq6CKcO6s6Ppwzl1EHd6dm5fbzLEzkmCgKRT+DuPDO/mF++VEjFvjq+NC5b0z5Im6MgEDmE99eXcfesQuZtKCe/fxZ3XDBSF31JmxRoEJjZFOAeIBmY7u53HmK7C4FngPHuXhBkTSKH8/76Mn776ireW7uTHp3SuPOLo7goP0dj/6XNCiwIzCwZuA84CygG5pnZTHdffsB2nYDrgblB1SISi6WbK7hr1kreWlVC94w0/vPzI7h0Yq5u+CJtXpBnBBOANe6+DsDMngSmAssP2O4XwK+AHwVYi8hBVdc18M7qUp5dUMxLS7eR2aEdPzlnGJdNyiM9VQEg4RBkEPQDNjVZLgYmNt3AzMYBOe7+DzM7ZBCY2TRgGkBubm4ApUrYrNq+h3teXc3rK3ewt7aBTu1TuG7yIK4+baBu9C6hE7fOYjNLAn4DXHG4bd39AeABgPz8fA+2MmnLqusauO/1Ndz/5lo6pKZwwdh+fO743kwa2I3UFF0EJuEUZBBsBnKaLGdH1+3XCRgJvGFmAL2BmWZ2njqMpTnt2F3Nok27WFxcwT+WbGV9aRVfHNuPW88dTreMtHiXJxJ3QQbBPGCwmQ2gMQAuBi7Z/6S7VwDd9y+b2RvAjQoBaS57a+v5+czlzChobKFMTjJG9u3Mn6+ayKmDux/m1SLhEVgQuHu9mV0LzKJx+OiD7r7MzG4HCtx9ZlDvLVK4bTfXPr6QtSWVfPNTA5gysjcj+nRRB7DIQQTaR+DuLwIvHrDup4fY9jNB1iLhsLe2ngffWc/vXltD5/R2/PmqiZwySJ/+RT6JriyWNqG+IcJTBcX89tVV7NhTw+eO78V/XTCK7uoDEDksBYG0etsqqrn28QUUFJVzYv8s7rt0HOPzusa7LJFWQ0Egrdp7a0u57omF7K1t4LdfGcPUMX2JjkITkRgpCKRV2lBaxaNzinj4vfUM6N6RJ6dNYlBPzQgqcjQUBNKqvLumlPvfXMvbq0tJSTIuHJfNbecdr3sBixwD/fZIq7CzsoY7/rGCvy7cTJ8u7bnhrCF8ZXyObgoj0gwUBJLw/rZoMz+buYzKmnqumzyI75w+SDOCijQjBYEkrN3Vdfzn80v526ItjM3N5FcXjmZIL/UDiDQ3BYEkpLnrdnLD0x+wtaKaG84awndOH0SybgwjEggFgSSUhRvLuWf2at5YWUJO13Se/tZJjMvNindZIm2agkASQuG23fzqpUJeX1lCVod23DRlGF8/qT8dNRpIJHD6LZO42lqxj1//cxXPLiimU1oKP54ylMtPylMAiLQg/bZJ3Ly8dBs3PLWIugbn6lMH8N3TB5HZITXeZYmEjoJAWlwk4vz21VXc+9oaTsjJ5P++Opacrh3iXZZIaCkIpEVV7K3jhqcX8eqKHXz5xGx+cf5IXRMgEmcKAmkxCzaW873HF7JjTzU/P+94vn5Sf00QJ5IAFAQSOHfnj2+v466XV9Insz1Pf+tkxuRkxrssEYlSEEig6hsi3PrXpcwo2MTZI3tz54Wj6ZLeLt5liUgTCgIJTHVdA997YiGvLN/OdZMH8YOzhqgpSCQBKQgkEJt37eP7Ty6koKicn593PJefnBfvkkTkEBQE0qz21Tbwh7fWcv+ba3GHey8eyxdO6BvvskTkEygIpNm8taqEW55bwuZd+zh3dB9uOXsY2Vm6PkAk0SkI5JhV1zVw18srefDd9QzqmcGMaZOYOLBbvMsSkRgpCOSYrCup5Dt/WUDhtj1cflJ/bjlnuC4QE2llYgoCM3sO+BPwkrtHgi1JWov315cx7bECksx46IrxnD6sZ7xLEpGjkBTjdv8PuARYbWZ3mtnQAGuSVuBvizbztelz6doxlee/c4pCQKQViykI3P1Vd78UGAdsAF41s/fM7Eoz09VBIRKJOL95ZRXXP7mIMbmZPPftk8ntpg5hkdYs5j4CM+sGfA24DFgI/AU4Fbgc+EwQxUliqdhbx/dnLOT1lSV86cRs/uuCkaSlqD9ApLWLtY/gr8BQ4DHgC+6+NfrUDDMrCKo4SRyrtu/h6kcK2FqxjzvOH8mlE3N1lbBIGxHrGcG97v76wZ5w9/xmrEcS0LItFXxt+lzaJScx4xrdQ1ikrYm1s3iEmX04XaSZZZnZdwKqSRLIkuIKLvnjXDqkpuhG8iJtVKxB8E1337V/wd3LgW8GU5IkisXFu7hk+r/o1D6FJ6dNon+3jvEuSUQCEGvTULKZmbs7gJklA7q5bBtWVlXLtEfn0yW9HTOuOYl+menxLklEAhLrGcHLNHYMn2FmZwBPRNd9IjObYmYrzWyNmd18kOe/ZWZLzGyRmb1jZiOOrHwJQiTi/PCpRZRV1XL/105UCIi0cbGeEdwEXAN8O7r8CjD9k14QPWu4DzgLKAbmmdlMd1/eZLPH3f3+6PbnAb8BpsRevgThgbfX8cbKEn4x9XhG9usS73JEJGAxBUF0WonfR79iNQFY4+7rAMzsSWAq8GEQuPvuJtt3BPwIvr8EoGBDGXfPWsm5o/rwtUn9412OiLSAWK8jGAz8EhgBtN+/3t0HfsLL+gGbmiwXAxMP8r2/C/yQxj6HyYd4/2nANIDc3NxYSpajsKS4gqseKSA7K51fXjhK1wmIhESsfQQP0Xg2UA+cDjwK/Lk5CnD3+9z9OBqbn/7jENs84O757p7fo0eP5nhbOcCiTR+NEPrzVRPp3F4zh4iERaxBkO7uswFz9yJ3/xlw7mFesxnIabKcHV13KE8C58dYjzSj+UXlXDZ9LlkdUplxzUnkdNXcQSJhEmsQ1JhZEo2zj15rZhcAGYd5zTxgsJkNMLNU4GJgZtMNok1O+50LrI6xHmkmm8r2ctUj8+iWkcqMayZphJBICMU6auh6oANwHfALGpuHLv+kF7h7vZldC8wCkoEH3X2Zmd0OFLj7TOBaMzsTqAPKD/c9pXntra3nm48WEIk4D185gT5dFAIiYXTYIIgOA/2Ku98IVAJXxvrN3f1F4MUD1v20yePrYy9VmpO786NnFrNq+x4eunICed111bBIWB22acjdG2icblrakPvfXMc/Fm/lx1OG8ekh6oAXCbNYm4YWmtlM4Gmgav9Kd38ukKokUHPW7uTuWYWcO7oP15z2SSOARSQMYg2C9sBOPj7O3wEFQStTsqeG655cSF63jvzqwtG6VkBEYr6yOOZ+AUlcDRHn+zMWsntfHY9+YwIZaTHfoE5E2rBYryx+iINM/+Du32j2iiQwv3ttNe+u2cmvLhzF8D6d412OiCSIWD8SvtDkcXvgAmBL85cjQfnbos389tXVfHFcPy7Kzzn8C0QkNGJtGnq26bKZPQG8E0hF0uzeW1vKjU9/wIQBXfnvCzSHkIh8XKxXFh9oMNCzOQuRYBRu2801j80nr1tH/nhZPu3bJce7JBFJMLH2Eezh430E22icJE4SWGllDd94aB4dUpN5+BsT6NJBE8mJyL+LtWmoU9CFSPOqb4jw3b8sYGdVLc9++2TNISQihxRT05CZXWBmXZosZ5qZZgpNYL98qZC568u488JRusuYiHyiWPsIbnP3iv0L7r4LuC2YkuRY/W3RZv70znquODmPC8Zmx7scEUlwsQbBwbbT1UgJaElxBTc9u5gJeV259dzh8S5HRFqBWIOgwMx+Y2bHRb9+A8wPsjA5ctsqqrn60Xl065jGfZeOo13y0Q4KE5EwifUvxfeAWmAGjXcSqwa+G1RRcuT21tZz9aPzqKyuZ/rl+fTolBbvkkSklYh11FAVcHPAtchRikScH874gOVbdjP98nxNHyEiRyTWUUOvmFlmk+UsM5sVXFlyJB54ex0vL9vGT84ZzuRhveJdjoi0MrE2DXWPjhQCwN3L0ZXFCWF+URl3z1rJOaN6c9WpA+Jdjoi0QrEGQcTMcvcvmFkeB5mNVFpWeVUt1z6+kH6Z6dypewuIyFGKdQjorcA7ZvYmYMCngGmBVSWHFYk4Nz79AaWVNTz77ZPp3F7TR4jI0YnpjMDdXwbygZXAE8ANwL4A65JP4O7c/sJyZhfu4CfnDGd0dubhXyQicgixTjp3NXA9kA0sAiYBc/j4rSulBbg7d81aycPvbeDqUwdwxcl58S5JRFq5WPsIrgfGA0XufjowFtj1yS+RINz3+hp+/8ZaLpmYy63nDle/gIgcs1iDoNrdqwHMLM3dC4GhwZUlB3J3fjd7Nf/zz1V8cWw/7pg6UiEgIs0i1s7i4uh1BM8Dr5hZOVAUXFnSlLvz3y+u4I9vr+eLY/tx15dGk5SkEBCR5hHrlcUXRB/+zMxeB7oALwdWlXyoIeL85LklzCjYxOUn9ee2LxyvEBCRZnXEM4i6+5tBFCL/riE6RPSvCzfzvcmD+OFZQ9QcJCLNTlNJJ6imIXDjZ4dw7eTB8S5JRNoozVOcgBQCItKSFAQJJhJxbnp2sUJARFqMgiCBuDu3zVzGM/OL+f6ZgxUCItIiFAQJwt355UuFPPavIq45bSDXn6EQEJGWoSBIEP/vjbU88NY6vn5Sf24+e5hGB4lIiwk0CMxsipmtNLM1ZvZvdzgzsx+a2XIzW2xms82sf5D1JKq/LdrM3bNWMnVMX372heMVAiLSogILAjNLBu4DzgZGAF81sxEHbLYQyHf30cAzwF1B1ZOo5m0o40dPL2ZCXlddMSwicRHkGcEEYI27r3P3Whpvej+16Qbu/rq7740u/ovG2U1DY0NpFdMeLaBfVjp/uOxE0lKS412SiIRQkEHQD9jUZLk4uu5QrgJeOtgTZjbNzArMrKCkpKQZS4yf7buruezBuQA8dMV4sjqmxrkiEQmrhOgsNrOv0Xjjm7sP9ry7P+Du+e6e36NHj5YtLgC79tZy2Z/mUlZZy0NXTiCve8d4lyQiIRbkFBObgZwmy9nRdR9jZmfSeCvMT7t7TYD1JISqmnqueGgeG0r38vCV4xmTo7uLiUh8BXlGMA8YbGYDzCwVuBiY2XQDMxsL/AE4z913BFhLwrj5uSUsLt7F7y4Zy8mDuse7HBGR4ILA3euBa4FZwArgKXdfZma3m9l50c3uBjKAp81skZnNPMS3axPeWV3K3z/YwnVnDOZzx/eOdzkiIkDAs4+6+4vAiwes+2mTx2cG+f6JpLY+wk9nLqV/tw5869PHxbscEZEPJURncRj86Z31rCup4rYvjKB9Ow0TFZHEoSBoAVt27ePe2as5a0QvJg/rFe9yREQ+RkEQsP0zikbc+ennD7ywWkQk/hQEAXt6fjGvLN/OD88aQk7XDvEuR0Tk3ygIArRx515+PnMZkwZ25epPDYx3OSIiB6UgCEh9Q4QfPLWIpCTj1xeNIVmTyYlIgtLN6wNy/5trmV9Uzj0Xj6FfZnq8yxEROSSdEQRg2ZYKfvvqaj4/ug9Tx3zSPHsiIvGnIGhmNfUN3PDUB2R1TOWO80fGuxwRkcNS01Azu+fV1RRu28ODV+ST2UFTS4tI4tMZQTNasLGc+99cy0X52bpwTERaDQVBM6mua+DGpz+gT5d0/lMXjolIK6KmoWby63+uZF1JFX++aiKd2reLdzkiIjHTGUEzKNhQxvR31nPpxFxOHax7DIhI66IgOEb7ahv40TOL6ZeZzi3nDI93OSIiR0xNQ8fo7lkrWV9axePfnEhGmv47RaT10RnBMViwsZyH3lvPZZP6c/JxahISkdZJQXCUausj3PLsEnp3bs9NZw+LdzkiIkdNbRlH6YG31rJy+x6mfz1fTUIi0qrpjOAorC2p5N7Zazh3VB/OHKELx0SkdVMQHKFIxLnluSW0b5fEbefpwjERaf0UBEfoiXkbeX99GbeeO5yendrHuxwRkWOmIDgCWyv28csXCzn5uG5clJ8T73JERJqFgiBG7s6tf11KfSTCnV8cjZnuOCYibYOCIEYzP9jCa4U7uPGzQ8ntppvQi0jboSCIwa69tfz878s5ISeTK08ZEO9yRESalQbAx+Ce2avZtbeWv1w9UTehF5E2R2cEh7G2pJLH5hTxlfG5DO/TOd7liIg0OwXBYfz3P1bQvl0yN3x2SLxLEREJhILgE7y9uoTZhTu4dvIgumekxbscEZFAKAgOob4hwh0vrCC3aweuPCUv3uWIiARGQXAID7+3gZXb9/CTc4aRlpIc73JERAKjIDiITWV7+fU/V3HGsJ587vje8S5HRCRQgQaBmU0xs5VmtsbMbj7I86eZ2QIzqzezLwVZS6zcnf94filmcPv5I3UFsYi0eYEFgZklA/cBZwMjgK+a2YHTdW4ErgAeD6qOIzXzgy28uaqEGz87lH6Z6fEuR0QkcEFeUDYBWOPu6wDM7ElgKrB8/wbuviH6XCTAOmJWsa+O2/++nBOyu3D5yXnxLkdEpEUE2TTUD9jUZLk4uu6Imdk0Mysws4KSkpJmKe5g3lpVws6qWv7j8yN0BbGIhEar6Cx29wfcPd/d83v06BHY+yzYWE56u2TG5GQG9h4iIokmyCDYDDSdtD87ui5hLSgqZ3R2F9olt4p8FBFpFkH+xZsHDDazAWaWClwMzAzw/Y5JdV0Dy7bsZlz/rHiXIiLSogILAnevB64FZgErgKfcfZmZ3W5m5wGY2XgzKwa+DPzBzJYFVc/hLC6uoD7inJirIBCRcAl0Gmp3fxF48YB1P23yeB6NTUZxt2BjOQBjc9U/ICLhosbwqAVF5Qzo3pFumlxOREJGQUDj1cQLNpbrbEBEQklBAGwq20dpZS3j1D8gIiGkIADmbywD4ESNGBKREFIQAAuKdpGRlsKQXp3iXYqISItTENA4YuiEnC6aVkJEQin0QVBVU8+Krbt1/YCIhFbog2Dhxl1EHMaqf0BEQir0QfDcgmI6paUwcUDXeJciIhIXoQ6CXXtreWHJVs4f248OqYFeZC0ikrBCHQR/XbiZ2voIX52QG+9SRETiJrRB4O488f5GTsjJZETfzvEuR0QkbkIbBAs2lrNqeyWXTMg5/MYiIm1YaIPg8bmbyEhL4fOj+8a7FBGRuAplEFTsq+OFxVuYOqYvHdPUSSwi4Raqv4K7q+t4at4mHnp3AzXqJBYRAUIUBDPmbeQXL6ygsqaeiQO68l8XjGRkvy7xLktEJO5CEwTZWR04Y3hPrj51IKOyFQAiIvuFJghOGdSdUwZ1j3cZIiIJJ5SdxSIi8hEFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIiIhZ+4e7xqOiJmVAEVH+fLuQGkzltNahHG/w7jPEM79DuM+w5Hvd39373GwJ1pdEBwLMytw9/x419HSwrjfYdxnCOd+h3GfoXn3W01DIiIhpyAQEQm5sAXBA/EuIE7CuN9h3GcI536HcZ+hGfc7VH0EIiLy78J2RiAiIgdQEIiIhFxogsDMppjZSjNbY2Y3x7ueIJhZjpm9bmbLzWyZmV0fXd/VzF4xs9XRf7PiXWtzM7NkM1toZi9ElweY2dzo8Z5hZqnxrrG5mVmmmT1jZoVmtsLMTgrJsf5B9Od7qZk9YWbt29rxNrMHzWyHmS1tsu6gx9Ya3Rvd98VmNu5I3y8UQWBmycB9wNnACOCrZjYivlUFoh64wd1HAJOA70b382ZgtrsPBmZHl9ua64EVTZZ/Bfyvuw8CyoGr4lJVsO4BXnb3YcAJNDWLuHIAAAR/SURBVO5/mz7WZtYPuA7Id/eRQDJwMW3veD8MTDlg3aGO7dnA4OjXNOD3R/pmoQgCYAKwxt3XuXst8CQwNc41NTt33+ruC6KP99D4h6Efjfv6SHSzR4Dz41NhMMwsGzgXmB5dNmAy8Ex0k7a4z12A04A/Abh7rbvvoo0f66gUIN3MUoAOwFba2PF297eAsgNWH+rYTgUe9Ub/AjLNrM+RvF9YgqAfsKnJcnF0XZtlZnnAWGAu0Mvdt0af2gb0ilNZQfkt8GMgEl3uBuxy9/rocls83gOAEuChaJPYdDPrSBs/1u6+GfgfYCONAVABzKftH2849LE95r9vYQmCUDGzDOBZ4Pvuvrvpc944XrjNjBk2s88DO9x9frxraWEpwDjg9+4+FqjigGagtnasAaLt4lNpDMK+QEf+vQmlzWvuYxuWINgM5DRZzo6ua3PMrB2NIfAXd38uunr7/lPF6L874lVfAE4BzjOzDTQ2+U2mse08M9p0AG3zeBcDxe4+N7r8DI3B0JaPNcCZwHp3L3H3OuA5Gn8G2vrxhkMf22P++xaWIJgHDI6OLEilsXNpZpxranbRtvE/ASvc/TdNnpoJXB59fDnwt5auLSjufou7Z7t7Ho3H9TV3vxR4HfhSdLM2tc8A7r4N2GRmQ6OrzgCW04aPddRGYJKZdYj+vO/f7zZ9vKMOdWxnAl+Pjh6aBFQ0aUKKjbuH4gs4B1gFrAVujXc9Ae3jqTSeLi4GFkW/zqGxzXw2sBp4Fega71oD2v/PAC9EHw8E3gfWAE8DafGuL4D9HQMURI/380BWGI418HOgEFgKPAaktbXjDTxBYx9IHY1nf1cd6tgCRuOoyLXAEhpHVB3R+2mKCRGRkAtL05CIiByCgkBEJOQUBCIiIacgEBEJOQWBiEjIKQhEosyswcwWNflqtgnbzCyv6UySIokk5fCbiITGPncfE+8iRFqazghEDsPMNpjZXWa2xMzeN7NB0fV5ZvZadA742WaWG13fy8z+amYfRL9Ojn6rZDP7Y3Qu/X+aWXp0++ui95BYbGZPxmk3JcQUBCIfST+gaegrTZ6rcPdRwP/RONspwO+AR9x9NPAX4N7o+nuBN939BBrn/1kWXT8YuM/djwd2ARdG198MjI1+n28FtXMih6Iri0WizKzS3TMOsn4DMNnd10Un9dvm7t3MrBTo4+510fVb3b27mZUA2e5e0+R75AGveONNRTCzm4B27n6Hmb0MVNI4TcTz7l4Z8K6KfIzOCERi44d4fCRqmjxu4KM+unNpnCtmHDCvySyaIi1CQSASm680+XdO9PF7NM54CnAp8Hb08Wzg2/DhvZS7HOqbmlkSkOPurwM3AV2AfzsrEQmSPnmIfCTdzBY1WX7Z3fcPIc0ys8U0fqr/anTd92i8Q9iPaLxb2JXR9dcDD5jZVTR+8v82jTNJHkwy8OdoWBhwrzfeclKkxaiPQOQwon0E+e5eGu9aRIKgpiERkZDTGYGISMjpjEBEJOQUBCIiIacgEBEJOQWBiEjIKQhERELu/wP8QpW9FnfgvQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISLZZGlQlSxh"
      },
      "source": [
        "### Generate better lyrics!\n",
        "\n",
        "This time around, we should be able to get a more interesting output with less repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P96oVMk3lU7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095bcd4f-ed7f-4689-e2a1-5b069a871cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "im feeling chills the light of a cat into my tongue were the sound of past to diddle to the happiest streets though the times are making past office adore ho tiger damn worlds come back crown having anything id lot past plane evil buy images tasted conceal baa conceal bet nee lights go wild of tree landslide y louder nosotros killer gritty conceal explain hate absentminded nancy miss hammer cherry are runner slow see lets lets theyll take playground each day dance in the street lights go round laughed success care whom whom take baa sky face are wide season everyday wants\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgJKV8_oRU9"
      },
      "source": [
        "### Varying the Possible Outputs\n",
        "\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
        "\n",
        "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lZe9gaJeoGVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e7ddb9-d699-419f-865d-bbc853266652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252\n"
          ]
        }
      ],
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ee7WKgRGrJy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c410dbb1-1e9c-4d95-d57d-58fc070692bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "im feeling chills blood my dust were the queen of the door yeah baby flash of world wing lost angel havent scenes killer conceal impossible feet conceal write take mercy mercy bet power fights rattlesnake escaping rocket turmoil cocoon lets nancy take me me home me right right down upon your knees been old hoppin bitch trees swing posses walks the beast is me what more missing a choice holdin evil killer evil havent scenes hot explain evil brillaba bet baa attic habia came jungles tambourine whom are hot realized write hate hello from theyre high smiling having from past old place runner\n"
          ]
        }
      ],
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ]
}